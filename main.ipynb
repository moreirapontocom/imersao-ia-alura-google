{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2bV2rr39zUwd4WCRpuhPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moreirapontocom/imersao-ia-alura-google/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WqBb87ob59S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lRJv4cxbB4o",
        "outputId": "7f14ec19-e7eb-4325-c5c5-c9afadf54529"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import requests as req\n",
        "import json\n",
        "import random\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "\n",
        "API_ENDPOINT = userdata.get('API_ENDPOINT')\n",
        "API_KEY = userdata.get('API_KEY')\n",
        "genai.configure(api_key=API_KEY)\n",
        "model = genai.GenerativeModel(\"models/gemini-pro\")\n",
        "\n",
        "model.start_chat()"
      ],
      "metadata": {
        "id": "GLDXrpRgdbG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET - Lista todas as mensagens da API\n",
        "# e adiciona na variável \"mensagens\"\n",
        "\n",
        "def getMensagens():\n",
        "  response = req.get(url=f\"{API_ENDPOINT}/alura-desafio/mensagens\")\n",
        "  if response.status_code != 200:\n",
        "    return []\n",
        "\n",
        "  return response.json()['messages']\n",
        "\n",
        "mensagens = getMensagens()\n",
        "totalMensagens = len(mensagens)"
      ],
      "metadata": {
        "id": "m_tRO_XB43KV"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega uma mensagem aleatória e exibe na tela.\n",
        "\n",
        "mensagens = getMensagens()\n",
        "random_index = random.randint(0, len(mensagens)-1)\n",
        "random_message = mensagens[random_index]\n",
        "\n",
        "display(Markdown(f\"![Recebam nossos abraços](https://cdn-icons-png.flaticon.com/256/1361/1361323.png \"\")\"))\n",
        "\n",
        "display(Markdown(f\"Mensagem de paz\"))\n",
        "display(Markdown(f\"#\\\"{random_message['message']}\\\"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "IuiuZMyK5PoJ",
        "outputId": "89936cfc-bb75-4e12-ff99-901e03819181"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "![Recebam nossos abraços](https://cdn-icons-png.flaticon.com/256/1361/1361323.png )"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Mensagem de paz"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#\"Desejamos que todos recuperem os bens perdidos nesta tragédia e que Deus traga conforto àqueles que perderam seus entes queridos.\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96J4xqflZvmF",
        "outputId": "09447f18-5e02-4690-8d93-ebd45a121159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva uma mensagem de conforto para as pessoas afetadas pelas chuvas no RS\n",
            "Desejamos que todos recuperem os bens perdidos nesta tragédia e que Deus traga conforto àqueles que perderam seus entes queridos.\n"
          ]
        }
      ],
      "source": [
        "# Solicita que o usuário escreva uma mensagem\n",
        "# Adiciona o input do usuário em \"user_message\"\n",
        "\n",
        "# display(Markdown(\"**Escreva uma mensagem de conforto para as pessoas afetadas pelas chuvas no RS**\"))\n",
        "print(\"Escreva uma mensagem de conforto para as pessoas afetadas pelas chuvas no RS\")\n",
        "user_message = input()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatena o meu prompt com a mensagem que o usuário escreveu\n",
        "# para fazer a solicitação da análise e adicionar alguns filtros\n",
        "# Estou solicitando a resposta num formato específico para decidir salvar\n",
        "# ou não no banco de dados dependendo do resultado da análise pelo modelo.\n",
        "\n",
        "message_to_analyze = \"\"\"Analise este texto para detectar algum tipo de abuso,\n",
        "  discurso de ódio, xingamentos ou qualquer coisa ofensiva.\n",
        "  Me informe também, em uma única palavra, o resultado da análise.\n",
        "  Me responda em um formato JSON com as chaves \"conclusao\" e \"explicacao\".\n",
        "  A \"conclusao\" deve ser somente \"ofensivo\" ou \"nao_ofensivo\".\n",
        "  Analise este texto\"\"\"\n",
        "\n",
        "# Envia a solicitação de análise para o model\n",
        "\n",
        "response = model.generate_content(f'{message_to_analyze}:{user_message}')\n",
        "responseText = response.text if response.text else '{message: \"error\"}'"
      ],
      "metadata": {
        "id": "1znNFf4Ia6aP"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a resposta do model para o formato JSON\n",
        "\n",
        "responseText_dict = json.loads(responseText)\n",
        "\n",
        "# Definição da função que vai salvar a frase (input) do usuário no banco de dados\n",
        "\n",
        "def saveMessage(modelConclusion):\n",
        "  data = { \"message\": user_message, \"model_conclusion\": modelConclusion }\n",
        "  req.post(url=f\"{API_ENDPOINT}/alura-desafio/mensagens\", json=data)\n",
        "  return\n",
        "\n",
        "finalMessage = \"\"\n",
        "\n",
        "# Se o modelo detectou o conteúdo (input do usuário) como \"nao_ofensivo\",\n",
        "# então a frase será salva no banco de dados (saveMessage()) e também solicito uma nova\n",
        "# mensagem para o modelo, pedindo um agradecimento.\n",
        "# Se não - conteúdo detectado como \"ofensivo\" - o modelo deverá\n",
        "# responder que a frase não será salva.\n",
        "\n",
        "if responseText_dict[\"conclusao\"] == \"nao_ofensivo\":\n",
        "  saveMessage(responseText_dict[\"conclusao\"])\n",
        "  finalMessage = \"\"\"Escreva uma mensagem, de no máximo 2 linhas, de\n",
        "    agradecimento ao usuário por ter enviado uma bela mensagem.\n",
        "    Escreva em nome de um grupo de pessoas agradecidas.\n",
        "    Não adicione o nome do usuário.\n",
        "    Informe também que a mensagem foi salva e será enviada para aqueles\n",
        "    que precisam ouvir uma palavra de esperança.\"\"\"\n",
        "else:\n",
        "  finalMessage = \"\"\"Informe ao usuário que a mensagem não será\n",
        "    publicada pois foi considerada ofensiva. Diga também que este é um\n",
        "    momento delicado e que devemos ter empatia pelo próximo.\"\"\"\n",
        "\n",
        "finalMessageContent = model.generate_content(finalMessage).text\n",
        "\n",
        "display(Markdown(f\"**{finalMessageContent}**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "HY4ZotHDg515",
        "outputId": "b2f9e710-7ac0-41b2-b659-66a14877989d"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Gratidão por suas gentis palavras que nos enchem de esperança e consolo. Sua mensagem foi registrada e será compartilhada com aqueles que precisam de luz em seus dias.**"
          },
          "metadata": {}
        }
      ]
    }
  ]
}